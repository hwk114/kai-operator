apiVersion: kai.io/v1alpha1
kind: InferenceTask
metadata:
  name: llama-cpp-inference
  namespace: default
spec:
  llama-cpp:
    modelPath: /models/llama-7b.gguf
    contextSize: 4096
    threads: 4
    port: 8080
